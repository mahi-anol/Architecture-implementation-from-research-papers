# Deep Learning Architectures: From-Scratch Implementations from Research Papers

In my free time, I enjoy implementing well-known deep learning architectures entirely from scratch (by following research papers) as a way to challenge and deepen my understanding of how they really work. This project is driven purely by curiosity and a passion for learning, rather than benchmarks or production goals.

Rebuilding these architectures layer by layer, wiring the training pipelines, and finally seeing the loss decrease is deeply rewarding. That moment when everything clicks, when the model trains correctly, gradients flow as expected, and theory turns into working code, is what motivates this repository.

Each implementation reflects my learning journey while studying the original research papers, aiming to translate ideas from theory into clean, readable, and modular code.

---

## Design Philosophy

The project adheres to the following principles:

- **From-scratch implementations**: Core logic (layers, blocks, etc.) is built ground-up with minimal external abstractions.
- **Readable and modular code**: Clear structure for easy understanding, debugging, and modification.
- **Paper-faithful architectures**: Strict adherence to the specifications in the original papers.
- **Scalable and extensible**: Easy adaptation to different datasets, tasks, and hardware.
- **Separation of concerns**: Dedicated modules for data handling, model definition, training logic, and utilities.

---

## üìÇ Repository Structure

Each architecture has its own isolated folder for clarity and independent experimentation.

```text
‚îú‚îÄ‚îÄ efficientnet/
‚îú‚îÄ‚îÄ resnet/
‚îú‚îÄ‚îÄ unet/
|__UNET++/
‚îî‚îÄ‚îÄ ... (more coming soon)
```


### Standard Folder Layout (per architecture)..Goto to src/

| File                  | Description                                                                 |
|-----------------------|-----------------------------------------------------------------------------|
| `model.py`            | Core neural network architecture implemented from scratch                   |
| `training_pipeline.py`| Training loop, validation, loss computation, and checkpointing              |
| `data_pipeline.py`    | Dataset loading, preprocessing, augmentations, and DataLoaders              |
| `config.py`           | Hyperparameters and experiment configuration                                |
| `main.py`             | Entry point ( empty for now)                                                |
| `utils.py`            | Helper functions (custom layers, check pointing methods, etc.)                             |
| `logger.py`           | Logging and experiment tracking utilities                                   |
| `exception.py`        | Custom exceptions for better error handling                                 |

---

##  Implemented Architectures

- **EfficientNet**: Compound scaling of depth, width, and resolution for efficient CNNs.
- **ResNet**: Deep residual learning with skip connections to enable very deep networks.
- **UNet**: Encoder-decoder architecture with skip connections for precise segmentation.
- (**more coming soon**)
---

## Future Plans

- [ ] Adding more architectures.

---

## üèÅ Getting Started

1. **Clone the repository**
   ```bash
   git clone https://github.com/mahi-anol/Architecture-implementation-from-research-papers.git
   cd *target-architecture-folder*
  
2. Install dependencies (recommended: create a virtual environment)
    ```bash
    pip install torch torchvision tqdm

3. Start training a architechture.
    Run an example (e.g., ResNet on CIFAR-10 or ImageNet-style dataset)
    ```bash
    python src/training_pipeline.py
    ```

## üìö References / Citations

- **EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks**  
  Mingxing Tan, Quoc Le, ICML 2019  
  [Paper Link](https://arxiv.org/abs/1905.11946)

- **Deep Residual Learning for Image Recognition**  
  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR 2016  
  [Paper Link](https://arxiv.org/abs/1512.03385)

- **U-Net: Convolutional Networks for Biomedical Image Segmentation**  
  Olaf Ronneberger, Philipp Fischer, Thomas Brox, MICCAI 2015  
  [Paper Link](https://arxiv.org/abs/1505.04597)
  
- **U-Net++: A Nested U-Net Architecture for Medical Image Segmentation**  
  Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, Jianming Liang, Deep Learning in Medical Image Analysis (DLMIA) Workshop, MICCAI 2018  
  [Paper Link](https://arxiv.org/abs/1807.10165)

